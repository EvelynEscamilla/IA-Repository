{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías\n",
    "\n",
    "os: Para manejar directorios y archivos.\n",
    "\n",
    "cv2: Librería OpenCV para procesamiento de imágenes.\n",
    "\n",
    "numpy: Para cálculos matemáticos y operaciones con matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de Procesamiento de Imágenes\n",
    "\n",
    "Implementé algunas funciones para tratar las imagenes, por lo que de una imagen se generan varias versiones, se guarda la imagen original y su versión con cada filtro.\n",
    "\n",
    "La primera de ellas es para ajustar el brillo y contraste, consideré que sería bueno implementar esta función ya que podría ayudar a mejorar la generalización del modelo al exponerlo a imágenes con diferentes niveles de iluminación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_brillo_contraste(frame, alpha=1.0, beta=0):\n",
    "    return cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra función es el recorte aleatorio, esto con la finalidad de extraer características específicas del coche, tomando en cuenta que en la imagenes podría salir solamente una parte del coche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recortar_aleatoriamente(frame, porcentaje=0.1):\n",
    "    h, w = frame.shape[:2]\n",
    "    dy, dx = int(h * porcentaje), int(w * porcentaje)\n",
    "    x1, y1 = np.random.randint(0, dx), np.random.randint(0, dy)\n",
    "    return frame[y1:h - dy + y1, x1:w - dx + x1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función de zoom es para simular diferentes distancias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_zoom(frame, factor=1.2):\n",
    "    h, w = frame.shape[:2]\n",
    "    nh, nw = int(h / factor), int(w / factor)\n",
    "    frame_zoom = frame[(h - nh) // 2:(h + nh) // 2, (w - nw) // 2:(w + nw) // 2]\n",
    "    return cv2.resize(frame_zoom, (w, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta versión de la imagen es para eliminar el ruido y que la imagen quede más clara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_ruido(frame):\n",
    "    return cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se aplican los filtros blanco y negro, para ayudar en la parte de la detección de bordes y formas, rgb para ayudar a la clasificación de coches de acuerdo a los patrones de color y el filtro de escala de grises para el análisis de patrones y texturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_filtros_basicos(frame, filtro):\n",
    "    if filtro == \"blanco_negro\":\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    elif filtro == \"rgb\":\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    elif filtro == \"escala_grises\":\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return cv2.merge([gray, gray, gray])\n",
    "    else:\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se rota la imagen en un rango de ángulos aleatorios y se redimensiona, además se aumenta la variación en las posiciones de los coches en las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotar_y_redimensionar(frame, angulo_max=30, tamaño=(128, 128)):\n",
    "    angulo = np.random.uniform(-angulo_max, angulo_max)\n",
    "    \n",
    "    h, w = frame.shape[:2]\n",
    "    centro = (w // 2, h // 2)\n",
    "    \n",
    "    matriz_rotacion = cv2.getRotationMatrix2D(centro, angulo, 1)\n",
    "    \n",
    "    imagen_rotada = cv2.warpAffine(frame, matriz_rotacion, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "    \n",
    "    imagen_redimensionada = cv2.resize(imagen_rotada, tamaño)\n",
    "    \n",
    "    return imagen_redimensionada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica rotaciones predefinidas de 15, 30, 45, 60 y 90 grados, útil para garantizar variaciones consistentes en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotar_varias_veces(frame, angulos=[15, 30, 45, 60, 90], tamaño=(128, 128)):\n",
    "    rotaciones = []\n",
    "    for angulo in angulos:\n",
    "        rotacion = rotar_y_redimensionar(frame, angulo_max=angulo, tamaño=tamaño)\n",
    "        rotaciones.append(rotacion)\n",
    "    return rotaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambiar_tono_saturacion(frame, alpha=1.2, beta=50):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsv[..., 0] = hsv[..., 0] * alpha + beta \n",
    "    hsv[..., 1] = hsv[..., 1] * alpha         \n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqupi se mandan a llamar las funciones de los filtros para crear las versiones de la imagen y guardarlas en formato jpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_versiones(output_folder, base_name, frame):\n",
    "    transformaciones = {\n",
    "        \"rotacion_volteo\": lambda img: cv2.flip(cv2.rotate(img, cv2.ROTATE_180), 1),\n",
    "        \"brillo_contraste\": lambda img: ajustar_brillo_contraste(img, alpha=1.5, beta=30),\n",
    "        \"desplazamiento_zoom\": lambda img: aplicar_zoom(img, factor=1.3),\n",
    "        \"recorte\": lambda img: recortar_aleatoriamente(img, porcentaje=0.2),\n",
    "        \"eliminacion_ruido\": lambda img: eliminar_ruido(img),\n",
    "        \"filtro_bn\": lambda img: aplicar_filtros_basicos(img, \"blanco_negro\"),\n",
    "        \"filtro_rgb\": lambda img: aplicar_filtros_basicos(img, \"rgb\"),\n",
    "        \"filtro_grises\": lambda img: aplicar_filtros_basicos(img, \"escala_grises\"),\n",
    "    }\n",
    "\n",
    "    for nombre, transformacion in transformaciones.items():\n",
    "        img_transformada = transformacion(frame)\n",
    "        cv2.imwrite(f\"{output_folder}/{base_name}_{nombre}.jpg\", img_transformada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqupi, creamos una carpeta para guardar el dataset en caso de que no exista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_dataset(video_url, output_folder, resolution=(28, 21), start_time=0, end_time=None):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se descarga el vídeo, en este caso de youtube con la librería yt_dlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydl_opts = {\n",
    "        'format': 'best',\n",
    "        'outtmpl': 'temp_video.%(ext)s',\n",
    "        'noplaylist': True,\n",
    "        'quiet': True,\n",
    "    }\n",
    "\n",
    "with ytdlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    info_dict = ydl.extract_info(video_url, download=False)\n",
    "    video_url = info_dict.get('url', None)\n",
    "    print(f\"Usando URL: {video_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procesan los fotogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calculan los fps, la duración del vídeo y los frames, en este caso de inicio y fin ya que se define de que segundo a que segundo se toma del vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = total_frames / fps\n",
    "print(f\"Duración del video: {duration:.2f} segundos\")\n",
    "    \n",
    "start_frame = int(start_time * fps)\n",
    "end_frame = int(end_time * fps) if end_time is not None else total_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee cada fotograma, se redimensiona, se guarda la imagen y genera las versiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "frame_count = start_frame\n",
    "img_count = 0\n",
    "\n",
    "cv2.namedWindow(\"Procesamiento\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Procesamiento\", 600, 400)\n",
    "\n",
    "while frame_count < end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Procesamiento\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "        print(\"Ejecución detenida\")\n",
    "        break\n",
    "\n",
    "    img_resized = cv2.resize(frame, resolution)\n",
    "\n",
    "    base_name = f\"frame_{img_count}\"\n",
    "    cv2.imwrite(f\"{output_folder}/{base_name}.jpg\", img_resized)\n",
    "\n",
    "    generar_versiones(output_folder, base_name, img_resized)\n",
    "\n",
    "    img_count += 1\n",
    "    frame_count += 1\n",
    "    print(f\"Procesando frame {frame_count}/{total_frames}...\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Dataset generado en {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqupi se establece, primero el url del vídeo con el que vamos a trabajar, después, la carpeta donde se va a guardar el dataset y el tiempo inicial y final, en segundos, de la parte que tomaremos del vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://youtu.be/pemqhq4qwDw?si=5k2_MW4CvE3bDWr0\" \n",
    "output_folder = \"C:/Users/ShiEu/Documents/dataset_coches\"\n",
    "start_time = 6\n",
    "end_time = 12\n",
    "generar_dataset(video_url, output_folder, start_time=start_time, end_time=end_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
